{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 会话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# create data\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data*0.1 + 0.3\n",
    "\n",
    "#create tnesorflow struvture start #\n",
    "Weights = tf.Variable(tf.random_uniform([1],-1,1))\n",
    "biases = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "y = Weights*x_data +biases\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y-y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "#init = tf.initialize_all_variables()\n",
    "init = tf.global_variables_initializer()\n",
    "#create tnesorflow struvture end #\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init) #improtant\n",
    "\n",
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 ==0:\n",
    "        print(step, sess.run(Weights),sess.run(biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "matrix1 = tf.constant([[3,3]])\n",
    "matrix2 = tf.constant([[2],\n",
    "                       [2]])\n",
    "product = tf.matmul(matrix1,matrix2)  #matrix multiply np.dot(m1,m2)\n",
    "# #method 1\n",
    "# sess = tf.Session()\n",
    "# result = sess.run(product)\n",
    "# print(result)\n",
    "# sess.close()\n",
    "\n",
    "#method 2\n",
    "with tf.Session() as sess:\n",
    "    result2 = sess.run(product)\n",
    "    print(result2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "state = tf.Variable(0,name='counter')\n",
    "# print(state.name)\n",
    "one = tf.constant(1)\n",
    "\n",
    "new_value = tf.add(state,one)\n",
    "update = tf.assign(state,new_value)\n",
    "\n",
    "init = tf.initialize_all_variables()#must have if difne variables\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 传入值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#input1 = tf.palceholder(tf.float32,[2,2])\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "\n",
    "output = tf.multiply(input1,input2)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(output,feed_dict = {input1:[7.],input2:[2.]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 10 构建添加层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "def add_layer(inputs,in_size,out_size,activation_function = None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size,out_size]),name = 'W')\n",
    "    biases = tf.Variable(tf.zeros([1,out_size])+0.1,name = 'b')\n",
    "    Wx_puls_b = tf.add(tf.matmul(inputs,Weights),biases)\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_puls_b \n",
    "    else:\n",
    "        outputs = activation_function(Wx_puls_b,)\n",
    "    return outputs\n",
    "\n",
    "x_data = np.linspace(-1,1,300)[:,np.newaxis]\n",
    "noise = np.random.normal(0,0.05,x_data.shape)\n",
    "y_data = np.square(x_data)-0.5+noise\n",
    "\n",
    "xs = tf.placeholder(tf.float32,[None,1],name='x_input')\n",
    "ys = tf.placeholder(tf.float32,[None,1],name = 'y_input')\n",
    "\n",
    "layer1 = add_layer(xs,1,10,activation_function = tf.nn.relu)\n",
    "prediction = add_layer(layer1,10,1,activation_function = None)\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                                    reduction_indices=[1]))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "#init = tf.initialize_all_variables()\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(x_data,y_data)\n",
    "plt.ion()\n",
    "#plt.show()\n",
    "#plt.show(block = False)\n",
    "\n",
    "\n",
    "for step in range(1000):\n",
    "    sess.run(train_step,feed_dict={xs:x_data,ys:y_data})\n",
    "    if step%50==0:\n",
    "        print(step,sess.run(loss,feed_dict={xs:x_data,ys:y_data}))\n",
    "        try:\n",
    "            ax.line.remove(lines[0])\n",
    "        except Exception:\n",
    "            pass\n",
    "        prediction_value = sess.run(prediction,feed_dict={xs:x_data})\n",
    "        \n",
    "        #plt.pause(0.1)\n",
    "        #plt.close()\n",
    "lines = ax.plot(x_data, prediction_value, 'r-', lw=5)\n",
    "# plt.scatter(x_data, prediction_value)\n",
    "# plt.pause(0.05)       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 tensorboard graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorboard --logdir=C://Users//Administrator//logs\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    with tf.name_scope('layer'):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name='W')\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name='b')\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "with tf.name_scope('inputs'):\n",
    "    xs = tf.placeholder(tf.float32, [None, 1], name='x_input') \n",
    "    ys = tf.placeholder(tf.float32, [None, 1], name='y_input')\n",
    " \n",
    "\n",
    "# add hidden layer\n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "# add output layer\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "# the error between prediciton and real data\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                                        reduction_indices=[1]))\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "#writer = tf.train.SummaryWriter(\"logs/\", sess.graph)\n",
    "writer = tf.summary.FileWriter(\"logs/\",sess.graph)\n",
    "# important step\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 tensorboard histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, n_layer, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    layer_name = 'layer%s' % n_layer\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name='W')\n",
    "            #tf.histogram_summary(layer_name + '/weights', Weights)\n",
    "            tf.summary.histogram(layer_name + '/weights', Weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name='b')\n",
    "            tf.summary.histogram(layer_name + '/biases', biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "        tf.summary.histogram(layer_name + '/outputs', outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# Make up some real data\n",
    "x_data = np.linspace(-1, 1, 300)[:, np.newaxis]\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "with tf.name_scope('inputs'):\n",
    "    xs = tf.placeholder(tf.float32, [None, 1], name='x_input')\n",
    "    ys = tf.placeholder(tf.float32, [None, 1], name='y_input')\n",
    "\n",
    "# add hidden layer\n",
    "l1 = add_layer(xs, 1, 10, n_layer=1, activation_function=tf.nn.relu)\n",
    "# add output layer\n",
    "prediction = add_layer(l1, 10, 1, n_layer=2, activation_function=None)\n",
    "\n",
    "# the error between prediciton and real data\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                                        reduction_indices=[1]))\n",
    "    #tf.scalar_summary('loss', loss)\n",
    "    tf.summary.scalar('loss',loss)\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "#merged = tf.merge_all_summaries()\n",
    "merged = tf.summary.merge_all()\n",
    "#writer = tf.train.SummaryWriter(\"logs/\", sess.graph)\n",
    "writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "# important step\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 50 == 0:\n",
    "        result = sess.run(merged,\n",
    "                          feed_dict={xs: x_data, ys: y_data})\n",
    "        writer.add_summary(result, i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 16 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data  \n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)  \n",
    "\n",
    "def add_layer(inputs,in_size,out_size,activation_function = None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size,out_size]),name = 'W')\n",
    "    biases = tf.Variable(tf.zeros([1,out_size])+0.1,name = 'b')\n",
    "    Wx_puls_b = tf.add(tf.matmul(inputs,Weights),biases)\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_puls_b \n",
    "    else:\n",
    "        outputs = activation_function(Wx_puls_b,)\n",
    "    return outputs\n",
    "\n",
    "def compute_accuracy(v_xs,v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction,feed_dict={x:v_xs})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1),tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    result = sess.run(accuracy,feed_dict={x:v_xs,y_:v_ys})\n",
    "    return result\n",
    "\n",
    "#define placeholder for inputs to netword\n",
    "x = tf.placeholder(\"float\", [None, 784])  #28*28\n",
    "y_ = tf.placeholder(\"float\", [None,10])\n",
    "\n",
    "#add ouyput layer\n",
    "prediction = add_layer(x,784,10,activation_function = tf.nn.softmax)\n",
    "\n",
    "#the error between prediction and real data 计算交叉熵:\n",
    "#cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(prediction),\n",
    "                                              reduction_indices=[1]))#loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(1001):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    if i%50 == 0:  \n",
    "#         correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "#         accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "#         print (\"step %d, training accuracy %g\"%(i, sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})))  \n",
    "          print(i,compute_accuracy(mnist.test.images,mnist.test.labels))\n",
    "# saver = tf.train.Saver()   \n",
    "# saver.save(sess, \"model_data/model.ckpt\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19 Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to path: my_net/save_net.ckpt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  \n",
    "import numpy as np\n",
    "\n",
    "#Save to file\n",
    "#remember to define the same dtype and shape when restore\n",
    "W = tf.Variable([[3,4,5],[6,7,8]],dtype = tf.float32,name = 'weights')\n",
    "b = tf.Variable([[3,6,9]],dtype = tf.float32,name = 'biases')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    save_path = saver.save(sess,\"my_net/save_net.ckpt\")\n",
    "    print(\"Save to path:\",save_path)\n",
    "    \n",
    "# #restore variables\n",
    "# #redefine the same dtype and shape when restore\n",
    "# W = tf.Variable(np.arange(6).reshape((2,3)),dtype = tf.float32,name = \"weights\")\n",
    "# b = tf.Variable(np.arange(3).reshape((1,3)),dtype = tf.float32,name = \"biases\")\n",
    "\n",
    "# #not need init step\n",
    "# saver = tf.train.Saver()\n",
    "# with tf.Session() as sess:\n",
    "#     saver.restore(sess,\"my_net/save_net.ckpt\")\n",
    "#     print(\"weights:\",sess.run(W))\n",
    "#     print(\"biases:\",sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  读取图片和模型教程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def imageprepare():\n",
    "    \"\"\"\n",
    "    This function returns the pixel values.\n",
    "    The imput is a png file location.\n",
    "    \"\"\"\n",
    "    file_name='images/3.png'#导入自己的图片地址\n",
    "    #in terminal 'mogrify -format png *.jpg' convert jpg to png\n",
    "    im = Image.open(file_name).convert('L')\n",
    "\n",
    "    im.save(\"images/sample.png\")\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    tv = list(im.getdata()) #get pixel values\n",
    "\n",
    "    #normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.\n",
    "    tva = [ (255-x)*1.0/255.0 for x in tv] \n",
    "    #print(tva)\n",
    "    return tva\n",
    "\n",
    "\"\"\"\n",
    "This function returns the predicted integer.\n",
    "The imput is the pixel values from the imageprepare() function.\n",
    "\"\"\"\n",
    "\n",
    "# Define the model (same as when creating the model file)\n",
    "result=imageprepare()\n",
    "\n",
    "#定义一些函数：分配系数函数、分配偏置函数、卷积函数、pooling函数  \n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')   \n",
    "\n",
    "#x是输入的图像，y_是对应的标签  \n",
    "x = tf.placeholder(tf.float32, [None, 784])  \n",
    "y_ = tf.placeholder(tf.float32, [None, 10])  \n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "#第1层卷积层，Receptive Field 5＊5，单个batch生成32通道数据  \n",
    "W_conv1 = weight_variable([5, 5, 1, 32])  \n",
    "b_conv1 = bias_variable([32])  \n",
    "#把图像向量还原成28＊28的图像  \n",
    "x_image = tf.reshape(x, [-1,28,28,1])  \n",
    "#第1个卷积层，使用了ReLU激活函数  \n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)  \n",
    "h_pool1 = max_pool_2x2(h_conv1)   \n",
    "#第2层卷积层，Receptive Field 5＊5，单个batch 32通道生成64通道数据  \n",
    "W_conv2 = weight_variable([5, 5, 32, 64])  \n",
    "b_conv2 = bias_variable([64])  \n",
    "#第2个卷积层  \n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)  \n",
    "h_pool2 = max_pool_2x2(h_conv2)  \n",
    "#全链接层系数  \n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])  \n",
    "b_fc1 = bias_variable([1024])  \n",
    "#全链接层：把64通道数据展开方便全链接  \n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])  \n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)  \n",
    "#全链层神经元使用dropout防止过拟合  \n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)  \n",
    "#softmax层系数  \n",
    "W_fc2 = weight_variable([1024, 10])  \n",
    "b_fc2 = bias_variable([10])  \n",
    "#softmax层  \n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)  \n",
    "\n",
    "\n",
    "#初始化\n",
    "#sess = tf.InteractiveSession()\n",
    "#init_op = tf.initialize_all_variables()\n",
    "init = tf.global_variables_initializer()  #新的方式\n",
    "#sess.run(tf.global_variables_initializer())  \n",
    "\"\"\"\n",
    "Load the model2.ckpt file\n",
    "file is stored in the same directory as this python script is started\n",
    "Use the model to predict the integer. Integer is returend as list.\n",
    "\n",
    "Based on the documentatoin at\n",
    "https://www.tensorflow.org/versions/master/how_tos/variables/index.html\n",
    "\"\"\"\n",
    "saver = tf.train.Saver()\n",
    "#saver.save(sess, \"model_data/model.ckpt\")  #训练完用来保存\n",
    "saver.restore(sess, 'model_data/model.ckpt') #调用\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) #初始化\n",
    "    saver.restore(sess, 'model_data/model.ckpt')#这里使用了之前保存的模型参数\n",
    "    #print (\"Model restored.\")\n",
    "\n",
    "    prediction=tf.argmax(y_conv,1)\n",
    "    predint=prediction.eval(feed_dict={x: [result],keep_prob: 1.0}, session=sess)\n",
    "    print(h_conv2)\n",
    "\n",
    "    print('recognize result:')\n",
    "    print(predint[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
